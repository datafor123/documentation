import{_ as t,c as o,a as i,o as n}from"./app-CkMCZFJW.js";const s="/assets/image-20250811175634324-Bb_nGLx0.png",a="/assets/image-20250811175728180-CzaaAdi4.png",r="/assets/image-20250811175825662-C_ntEHh0.png",d="/assets/image-20250811175923560-D9PKb9iJ.png",l={};function c(p,e){return n(),o("div",null,e[0]||(e[0]=[i('<p>This guide explains how to connect and manage Large Language Models (LLMs) in Datafor so the AI Assistant can use providers such as OpenAI, Google Gemini, IBM watsonx, and Alibaba Qwen.</p><hr><h2 id="_1-open-the-model-settings-panel" tabindex="-1"><a class="header-anchor" href="#_1-open-the-model-settings-panel"><span>1) Open the Model Settings panel</span></a></h2><ol><li><p>Click <strong>Model Settings</strong> on the top toolbar.</p><div align="left"><img src="'+s+'"></div></li><li><p>In the right-side panel you can:</p><ul><li><strong>Add Model</strong> to create a new connection,</li><li><strong>Edit</strong> an existing model,</li><li><strong>View usage</strong> (chart icon),</li><li><strong>Delete</strong> a model (trash icon).</li></ul><div align="left"><img src="'+a+'" width="30%"></div></li></ol><p>You can switch the <strong>Current LLM</strong> from the drop-down at the top of the page before starting a new conversation.</p><h2 id="_2-add-or-edit-a-model" tabindex="-1"><a class="header-anchor" href="#_2-add-or-edit-a-model"><span>2) Add or edit a model</span></a></h2><p>Open <strong>Add Model</strong> or <strong>Edit</strong> on a listed model to see the form. Fill the fields as below:</p><ul><li><p><strong>Model Name</strong> <em>(required)</em> A human-friendly name (e.g., <code>gpt-4o-mini</code>, <code>gemini-2.0-flash</code>, <code>qwen-max-2025-01-25</code>).</p></li><li><p><strong>Description</strong> <em>(required)</em> Short text to help teammates recognize the model (e.g., <code>OpenAI gpt-4o-mini</code>, <code>IBM llama-3.3-70B instruct</code>).</p></li><li><p><strong>API Endpoint (Base URL)</strong> <em>(required)</em> The provider base URL (see reference in Section 3).</p></li><li><p><strong>API Key</strong> <em>(required)</em> Your provider key with permission to call the selected model.</p></li><li><p><strong>Extra Parameters (JSON, optional)</strong> Provider-specific fields (e.g., project/workspace ID). Must be valid JSON, for example:</p><div class="language-json line-numbers-mode" data-ext="json" data-title="json"><button class="copy" title="Copy code" data-copied="Copied"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">{</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">project_id</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">311f8a30-df8f-4bb4-9c30-d64b4fc2358e</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p><strong>Input Cost / Output Cost</strong> <em>(currently unused)</em> These are placeholders for future budgeting/quotas. They <strong>do not affect</strong> model usage yet. <strong>Recommendation:</strong> leave both as <code>0</code>.</p></li></ul><div align="left"><img src="'+r+'" width="34%"></div><p>Click <strong>OK</strong> to save.</p><h2 id="_3-provider-quick-reference" tabindex="-1"><a class="header-anchor" href="#_3-provider-quick-reference"><span>3) Provider quick reference</span></a></h2><table><thead><tr><th>Provider</th><th>Typical Base URL (API Endpoint)</th><th>Model name(s) (examples)</th><th>Extra Parameters</th></tr></thead><tbody><tr><td><strong>OpenAI</strong></td><td><code>https://api.openai.com/v1/</code></td><td><code>gpt-4o</code>, <code>gpt-4.1</code>, <code>gpt-3.5-turbo</code></td><td>None in most cases</td></tr><tr><td><strong>Google Gemini (OpenAI-compatible)</strong></td><td><code>https://generativelanguage.googleapis.com/v1beta/openai/</code></td><td><code>gemini-1.5-pro</code>, <code>gemini-2.0-flash</code></td><td>None; ensure the key has Generative Language access</td></tr><tr><td><strong>IBM watsonx</strong></td><td><code>https://eu-de.ml.cloud.ibm.com</code></td><td><code>meta-llama/llama-3-3-70b-instruct</code></td><td><code>{&quot;project_id&quot;:&quot;&lt;your-project-id&gt;&quot;}</code> (required)</td></tr><tr><td><strong>Alibaba Qwen (DashScope compatible)</strong></td><td><code>https://dashscope.aliyuncs.com/compatible-mode/v1</code></td><td><code>qwen-max</code>, <code>qwen-plus</code>, <code>qwen-turbo</code></td><td>Usually none</td></tr></tbody></table><blockquote><p>Tip: If a provider offers an <strong>OpenAI-compatible</strong> endpoint, use it to simplify setup.</p></blockquote><h2 id="_4-switch-and-manage-models" tabindex="-1"><a class="header-anchor" href="#_4-switch-and-manage-models"><span>4) Switch and manage models</span></a></h2><ul><li><p><strong>Switch default model</strong> Use the <strong>Current LLM</strong> drop-down at the top of the page. New chats will use this model by default.</p></li><li><p><strong>Per-model actions</strong> (in the right list):</p><ul><li><strong>Usage</strong> (chart icon): view call counts/usage trends.</li><li><strong>Edit</strong> (gear/pencil): update endpoint, key, extra parameters.</li><li><strong>Delete</strong> (trash): remove the connection.</li><li><strong>Quota badge</strong> (e.g., <em>Default Quota: 5 times/day</em>): shows the default call allowance for that model (if configured by admins).</li></ul><div align="left"><img src="'+d+'" width="34%"></div></li></ul><h2 id="_5-validate-the-connection" tabindex="-1"><a class="header-anchor" href="#_5-validate-the-connection"><span>5) Validate the connection</span></a></h2><ol><li>Save the model and set it as <strong>Current LLM</strong>.</li><li>Start a <strong>New Conversation</strong> and ask a sample question.</li><li>If the call fails, check: <ul><li>The <strong>API Endpoint</strong> matches the provider format (e.g., includes <code>/v1</code> or <code>/openai/</code> where required).</li><li>The <strong>API Key</strong> is valid, active, and has product access.</li><li>Required <strong>Extra Parameters</strong> are present (e.g., watsonx <code>project_id</code>).</li><li>Your network allows outbound HTTPS to the provider (proxy/firewall rules).</li></ul></li></ol>',17)]))}const h=t(l,[["render",c]]),m=JSON.parse('{"path":"/documentation/AI-Agent/LLM-Configuration/","title":"LLM Configuration","lang":"en-US","frontmatter":{"title":"LLM Configuration","permalink":"/documentation/AI-Agent/LLM-Configuration/","createTime":"2025/08/18 13:59:56"},"headers":[],"readingTime":{"minutes":1.81,"words":543},"git":{},"filePathRelative":"documentation/AI-Agent/10-LLM-Configuration.md"}');export{h as comp,m as data};
